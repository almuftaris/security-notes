Recent incidents involving AI

**Date**: February 3, 2026

## Malicious Chrome Extensions Targeting ChatGPT Users

malicious chrome extensions were discovered that introduce vulnerabilities for chatGPT users and compromises their data, potentially letting hackers view their chat history 

**Source**: [LayerX Security](https://layerxsecurity.com/blog/how-we-discovered-a-campaign-of-16-malicious-extensions-chatgpt/)

## RedKitten: AI-Accelerated Campaign Targeting Iranian Protests
HarfangLab identified a threat actor using AI tools to generate and deploy phishing campaigns targeting Iranian protestors.

**Source**: [HarfangLab](https://harfanglab.io/insidethelab/redkitten-ai-accelerated-campaign-targeting-iranian-protests/)

## Silent Brothers: Anonymous AI Network Beyond Platform Guardrails
SentinelOne Labs uncovered a network of compromised Ollama hosts forming an anonymous AI infrastructure used to bypass content restrictions and safety guardrails. The distributed network allows threat actors to run AI models without platform oversight or ethical constraints.

**Source**: [SentinelOne Labs](https://www.sentinelone.com/labs/silent-brothers-ollama-hosts-form-anonymous-ai-network-beyond-platform-guardrails/)

## Key themes
- Browser extensions remain a significant attack vector for credential and data theft, which is particularly critical given the large amount of personal and sensetive data that Frontier AI Labs (OpenAI, Anthropic, Google, Meta, etc) possess
- AI tools are being weaponized by threat actors to accelerate campaign development
- Distributed AI infrastructure is emerging as a method to bypass security controls

## Questions to Explore
- How can users verify the legitimacy of browser extensions before installation?
- What detection methods exist for AI-generated phishing content?
- What are the security implications of decentralized AI hosting platforms?

